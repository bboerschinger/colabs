{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JAX_MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKD4Xrbxv+PR6jB8cDivGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "336d7c7c1eb347369a9c045f61b35277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e606e4321dc4a88b77dc2c88388607d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8522196658804a0ba8347d4f0312468d",
              "IPY_MODEL_ec06fbbd4c2546c9ba1ea15e439f6ec5"
            ]
          }
        },
        "1e606e4321dc4a88b77dc2c88388607d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8522196658804a0ba8347d4f0312468d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c23656dc4ad4bb5858b8d4d094fe898",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_533be40a82104c0b966f8ff3cd051e23"
          }
        },
        "ec06fbbd4c2546c9ba1ea15e439f6ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07192f175df7445ebe8dd9cd5dd3b809",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:01&lt;00:00,  3.65 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ca0e5d988fc498483fe3000be8f3f4e"
          }
        },
        "8c23656dc4ad4bb5858b8d4d094fe898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "533be40a82104c0b966f8ff3cd051e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07192f175df7445ebe8dd9cd5dd3b809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ca0e5d988fc498483fe3000be8f3f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bboerschinger/colabs/blob/master/JAX_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmU5C_y7TQH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHyaSLMyzpne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3bb10fc-6a22-4d7c-e92c-e7290a388231"
      },
      "source": [
        "## Only if you have a TPU runtime.\n",
        "# Colab runtime set to TPU accel\n",
        "import requests\n",
        "import os\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "  url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver_nightly'\n",
        "  resp = requests.post(url)\n",
        "  TPU_DRIVER_MODE = 1\n",
        "\n",
        "# TPU driver as backend for JAX\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "print(config.FLAGS.jax_backend_target)\n",
        "\n",
        "# Source: Cloud TPU NeurIPS 2019 Colab."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grpc://10.56.104.226:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkYcBZhzattq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helpers to keep tracks of names and parameters.\n",
        "def create_name_scope():\n",
        "  names = set()\n",
        "\n",
        "  def make_name_fn(local_name):\n",
        "    tmp_name = local_name\n",
        "    i = 0\n",
        "    while tmp_name in names:\n",
        "      i += 1\n",
        "      tmp_name = f'{local_name}:{i}'\n",
        "    \n",
        "    names.add(tmp_name)\n",
        "    return tmp_name       \n",
        "\n",
        "  return make_name_fn\n",
        "\n",
        "def create_model():\n",
        "  scope = create_name_scope()\n",
        "  params = {}\n",
        "\n",
        "  def add_layer_fn(layer_call_fn_layer_params):\n",
        "    layer_call_fn, layer_params = layer_call_fn_layer_params\n",
        "    params.update(layer_params)\n",
        "    return layer_call_fn\n",
        "\n",
        "  return params, scope, add_layer_fn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESoP-kpcWY4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper for random numbers.\n",
        "def make_random_generator(seed):\n",
        "  rng = jax.random.PRNGKey(seed=seed)\n",
        "\n",
        "  def call_fn(num=1):\n",
        "    nonlocal rng\n",
        "    new_rngs = jax.random.split(key=rng, num=num+1)\n",
        "    rng = new_rngs[0]\n",
        "    if len(new_rngs[1:]) == 1:\n",
        "      return new_rngs[1]\n",
        "    else:\n",
        "      return new_rngs[1:]\n",
        "\n",
        "  return call_fn\n",
        "\n",
        "rng_fn = make_random_generator(seed=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTisWuGTW5ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helpers when defining layers.\n",
        "def make_local_getter(params, local_to_global):\n",
        "  def get_fn(local_name):\n",
        "    return params[local_to_global[local_name]]\n",
        "  \n",
        "  return get_fn\n",
        "\n",
        "\n",
        "def make_local_setter(params, local_to_global, scope):\n",
        "  def set_fn(local_name, value):\n",
        "    local_to_global[local_name] = scope(local_name)\n",
        "    params[local_to_global[local_name]] = value\n",
        "  \n",
        "  return set_fn"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhE5lP1zzBz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sgd_update(params, gradients, learning_rate):\n",
        "  return {\n",
        "      k: v - learning_rate * gradients[k] for (k, v) in params.items()\n",
        "  }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBy0I_NeTWVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example layer - simple feed forward network.\n",
        "def make_ffn(num_in, num_out, rng_fn, activation_fn, scope):\n",
        "  _local_to_global = {}\n",
        "  _params = {}\n",
        "\n",
        "  add_weight = make_local_setter(params=_params, \n",
        "                                 local_to_global=_local_to_global,\n",
        "                                 scope=scope)\n",
        "  \n",
        "  add_weight('W', jax.random.normal(key=rng_fn(), shape=(num_in, num_out)))\n",
        "  add_weight('b', jax.random.normal(key=rng_fn(), shape=(num_out,)))\n",
        "\n",
        "  def call_fn(inputs, params, rng, training):\n",
        "    \"\"\"\n",
        "      inputs:  [batch_size, num_in]\n",
        "    \"\"\"\n",
        "    get_weight = make_local_getter(params=params,\n",
        "                                   local_to_global=_local_to_global)\n",
        "    \n",
        "    # [batch_size, num_out]\n",
        "    activations = inputs @ get_weight('W') + get_weight('b')\n",
        "\n",
        "    if activation_fn is not None:\n",
        "      activations = activation_fn(activations)  \n",
        "\n",
        "    return activations\n",
        "\n",
        "  return (call_fn, _params)\n",
        "\n",
        "def make_residual_layer(wrapped_layer):\n",
        "  def call_fn(inputs, params, rng, training):\n",
        "    return inputs + wrapped_layer(inputs, params, rng, training)\n",
        "\n",
        "  return call_fn"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b93XUsj36sH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_layernorm(num_in, scope):\n",
        "  # Basically, see equations 15 and 16 in https://arxiv.org/pdf/1607.06450.pdf.\n",
        "  _local_to_global = {}\n",
        "  _params = {}\n",
        "\n",
        "  add_weight = make_local_setter(params=_params, \n",
        "                                 local_to_global=_local_to_global,\n",
        "                                 scope=scope)\n",
        "  \n",
        "  # Apparently alpha always gets initialized with zeros, and beta with ones...\n",
        "  # See https://arxiv.org/pdf/1607.06450.pdf, pages 13f.\n",
        "  add_weight('alpha', jax.numpy.zeros(shape=(num_in,)))\n",
        "  add_weight('beta', jax.numpy.ones(shape=(num_in,)))\n",
        "\n",
        "  def call_fn(inputs, params, rng, training):\n",
        "    \"\"\"inputs:  [batch_size, num_ins]\"\"\"\n",
        "    get_weight = make_local_getter(params=params,\n",
        "                                   local_to_global=_local_to_global)\n",
        "    \n",
        "    # For broadcasting to work, need to add a fake dimension at end.\n",
        "    # [batch_size, 1]\n",
        "    mu = jax.numpy.expand_dims(jax.numpy.mean(inputs, axis=-1), axis=1)\n",
        "    # [batch_size, 1]\n",
        "    sigma = jax.numpy.expand_dims(jax.numpy.std(inputs, axis=-1), axis=1)\n",
        "\n",
        "    return ((inputs-mu) / sigma) * get_weight('alpha') + get_weight('beta')\n",
        "\n",
        "  return (call_fn, _params)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We27kW6LpoEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470,
          "referenced_widgets": [
            "336d7c7c1eb347369a9c045f61b35277",
            "1e606e4321dc4a88b77dc2c88388607d",
            "8522196658804a0ba8347d4f0312468d",
            "ec06fbbd4c2546c9ba1ea15e439f6ec5",
            "8c23656dc4ad4bb5858b8d4d094fe898",
            "533be40a82104c0b966f8ff3cd051e23",
            "07192f175df7445ebe8dd9cd5dd3b809",
            "5ca0e5d988fc498483fe3000be8f3f4e"
          ]
        },
        "outputId": "b4dfa0a0-51ac-48fc-a3c8-1e0fc9aa1675"
      },
      "source": [
        "# Load mnist_data.\n",
        "mnist_data = tfds.load('mnist')\n",
        "train_data, test_data = mnist_data['train'], mnist_data['test']\n",
        "\n",
        "image_spec = train_data.element_spec['image']\n",
        "input_dimensionality = image_spec.shape[0] * image_spec.shape[1]\n",
        "\n",
        "number_of_classes = 10\n",
        "\n",
        "plt.imshow(next(iter(train_data))['image'].numpy().squeeze())\n",
        "\n",
        "# Flatten the images and turn things into numpy arrays.\n",
        "def mnist_adapter(mnist_data, batch_size):\n",
        "  def data_fn():\n",
        "    for batch in mnist_data.batch(batch_size):\n",
        "      image, label = batch['image'].numpy(), batch['label'].numpy()\n",
        "      image = jax.numpy.reshape(image, newshape=(-1, input_dimensionality))\n",
        "      yield (image, label)\n",
        "  \n",
        "  return data_fn\n",
        "\n",
        "train_data_fn = mnist_adapter(mnist_data=train_data, batch_size=512)\n",
        "dev_data_fn = mnist_adapter(mnist_data=test_data, batch_size=1024)  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "336d7c7c1eb347369a9c045f61b35277",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptioâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khgoKrciZ8D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model.\n",
        "\n",
        "model_params, model_scope, add_layer_fn = create_model()\n",
        "rng_fn = make_random_generator(seed=0)\n",
        "\n",
        "def make_sequential_model(layers):\n",
        "  def model_fn(inputs, params, rng, training):\n",
        "    for layer_fn in layers:\n",
        "      inputs = layer_fn(inputs=inputs,\n",
        "                        params=params,\n",
        "                        rng=rng,\n",
        "                        training=training)\n",
        "    return inputs\n",
        "  \n",
        "  return model_fn\n",
        "\n",
        "model_fn = jax.jit(make_sequential_model([\n",
        "  add_layer_fn(make_ffn(num_in=input_dimensionality, \n",
        "                        num_out=128, \n",
        "                        rng_fn=rng_fn, \n",
        "                        activation_fn=jax.nn.sigmoid, \n",
        "                        scope=model_scope)),\n",
        "  add_layer_fn(make_layernorm(num_in=128, scope=model_scope)),\n",
        "  add_layer_fn(make_ffn(num_in=128, \n",
        "                        num_out=64, \n",
        "                        rng_fn=rng_fn, \n",
        "                        activation_fn=jax.nn.sigmoid, \n",
        "                        scope=model_scope)),\n",
        "  add_layer_fn(make_layernorm(num_in=64, scope=model_scope)),\n",
        "  add_layer_fn(make_ffn(num_in=64, \n",
        "                        num_out=32, \n",
        "                        rng_fn=rng_fn, \n",
        "                        activation_fn=jax.nn.sigmoid, \n",
        "                        scope=model_scope)),\n",
        "  add_layer_fn(make_layernorm(num_in=32, scope=model_scope)),\n",
        "  add_layer_fn(make_ffn(num_in=32,\n",
        "                        num_out=10,\n",
        "                        rng_fn=rng_fn, \n",
        "                        activation_fn=None, \n",
        "                        scope=model_scope)),\n",
        "]))\n",
        "\n",
        "# Define a loss function.\n",
        "def make_cross_entropy_loss(model_fn): \n",
        "  def loss_fn(params, inputs, labels):\n",
        "    # [batch_size, number_of_classes]\n",
        "    logits = model_fn(params=params, inputs=inputs, rng=None, training=None)\n",
        "    \n",
        "    # [batch_size, number_of_classes]\n",
        "    one_hot_labels = jax.nn.one_hot(x=labels,\n",
        "                                    num_classes=number_of_classes)\n",
        "    \n",
        "    # [batch_size, number_of_classes]  \n",
        "    log_probs = jax.nn.log_softmax(logits)\n",
        "\n",
        "    log_loss = -log_probs * one_hot_labels\n",
        "\n",
        "    return jax.numpy.mean(log_loss)\n",
        "\n",
        "  return jax.jit(loss_fn)\n",
        "\n",
        "# Define an eval function.\n",
        "def make_accuracy_eval_fn(model_fn):\n",
        "  def eval_fn(params, data_fn):\n",
        "    num_examples = 0\n",
        "    num_correct = 0\n",
        "    for image, label in data_fn():\n",
        "      num_examples += image.shape[0]\n",
        "      logits = model_fn(params=params, inputs=image, rng=None, training=None)\n",
        "      prediction = jax.numpy.argmax(logits, axis=-1)\n",
        "      correct = prediction == label\n",
        "      num_correct += jax.numpy.sum(correct)\n",
        "    return num_correct / num_examples\n",
        "\n",
        "  return eval_fn  \n",
        "\n",
        "grad_loss_fn = jax.value_and_grad(fun=make_cross_entropy_loss(model_fn))\n",
        "accuracy_eval_fn = make_accuracy_eval_fn(model_fn)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arrAUPoxu4xK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2c6ce04-22e1-4637-c382-93e7095d7ad2"
      },
      "source": [
        "learning_rate = 1.0\n",
        "\n",
        "for epoch in range(100):\n",
        "  epoch_loss = 0.0\n",
        "  batches = 0\n",
        "  for (image, label) in train_data_fn():\n",
        "    loss, grad = grad_loss_fn(model_params, inputs=image, labels=label)\n",
        "    epoch_loss += loss\n",
        "    batches += 1\n",
        "    model_params = sgd_update(params=model_params,\n",
        "                              gradients=grad,\n",
        "                              learning_rate=learning_rate)\n",
        "  train_acc = accuracy_eval_fn(params=model_params, data_fn=train_data_fn)\n",
        "  dev_acc = accuracy_eval_fn(params=model_params, data_fn=dev_data_fn)\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, loss={epoch_loss/batches}, '\n",
        "        f'train_accuracy={train_acc}, dev_accuracy={dev_acc}')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss=0.2509215176105499, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 2, loss=0.2321443408727646, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 3, loss=0.23210103809833527, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 4, loss=0.23193079233169556, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 5, loss=0.23186546564102173, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 6, loss=0.23166771233081818, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 7, loss=0.2317083775997162, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 8, loss=0.23168830573558807, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 9, loss=0.23157522082328796, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 10, loss=0.23143240809440613, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 11, loss=0.23132050037384033, train_accuracy=0.11236666887998581, dev_accuracy=0.11349999904632568\n",
            "Epoch: 12, loss=0.23020072281360626, train_accuracy=0.1777999997138977, dev_accuracy=0.1818999946117401\n",
            "Epoch: 13, loss=0.21354681253433228, train_accuracy=0.24445000290870667, dev_accuracy=0.24859999120235443\n",
            "Epoch: 14, loss=0.1860937625169754, train_accuracy=0.39381667971611023, dev_accuracy=0.38839998841285706\n",
            "Epoch: 15, loss=0.15960463881492615, train_accuracy=0.4868333339691162, dev_accuracy=0.4892999827861786\n",
            "Epoch: 16, loss=0.14007879793643951, train_accuracy=0.5508833527565002, dev_accuracy=0.5593000054359436\n",
            "Epoch: 17, loss=0.12639541923999786, train_accuracy=0.584683358669281, dev_accuracy=0.5916999578475952\n",
            "Epoch: 18, loss=0.11651647835969925, train_accuracy=0.6109166741371155, dev_accuracy=0.6168000102043152\n",
            "Epoch: 19, loss=0.10858470946550369, train_accuracy=0.590499997138977, dev_accuracy=0.5895000100135803\n",
            "Epoch: 20, loss=0.10327623784542084, train_accuracy=0.6031000018119812, dev_accuracy=0.6065999865531921\n",
            "Epoch: 21, loss=0.0968548059463501, train_accuracy=0.6616666913032532, dev_accuracy=0.6620000004768372\n",
            "Epoch: 22, loss=0.09274470061063766, train_accuracy=0.5979999899864197, dev_accuracy=0.5924000144004822\n",
            "Epoch: 23, loss=0.08934742957353592, train_accuracy=0.6727333664894104, dev_accuracy=0.67249995470047\n",
            "Epoch: 24, loss=0.08510659635066986, train_accuracy=0.6685166954994202, dev_accuracy=0.6696000099182129\n",
            "Epoch: 25, loss=0.08277542144060135, train_accuracy=0.7076666951179504, dev_accuracy=0.7107999920845032\n",
            "Epoch: 26, loss=0.07935456931591034, train_accuracy=0.7610499858856201, dev_accuracy=0.7597000002861023\n",
            "Epoch: 27, loss=0.07719241827726364, train_accuracy=0.7127833366394043, dev_accuracy=0.7091000080108643\n",
            "Epoch: 28, loss=0.07706035673618317, train_accuracy=0.7563499808311462, dev_accuracy=0.7578999996185303\n",
            "Epoch: 29, loss=0.07388406246900558, train_accuracy=0.7347999811172485, dev_accuracy=0.7304999828338623\n",
            "Epoch: 30, loss=0.07157266139984131, train_accuracy=0.7718166708946228, dev_accuracy=0.7730000019073486\n",
            "Epoch: 31, loss=0.07026780396699905, train_accuracy=0.773983359336853, dev_accuracy=0.7703999876976013\n",
            "Epoch: 32, loss=0.06811720877885818, train_accuracy=0.787766695022583, dev_accuracy=0.7894999980926514\n",
            "Epoch: 33, loss=0.0673692375421524, train_accuracy=0.7809833288192749, dev_accuracy=0.7825999855995178\n",
            "Epoch: 34, loss=0.06621138751506805, train_accuracy=0.7956833243370056, dev_accuracy=0.7943999767303467\n",
            "Epoch: 35, loss=0.06428762525320053, train_accuracy=0.7713666558265686, dev_accuracy=0.7670999765396118\n",
            "Epoch: 36, loss=0.06381405144929886, train_accuracy=0.7997333407402039, dev_accuracy=0.7996000051498413\n",
            "Epoch: 37, loss=0.062268227338790894, train_accuracy=0.8060333132743835, dev_accuracy=0.8014000058174133\n",
            "Epoch: 38, loss=0.06129422038793564, train_accuracy=0.8046666979789734, dev_accuracy=0.8026999831199646\n",
            "Epoch: 39, loss=0.05990009754896164, train_accuracy=0.7853500247001648, dev_accuracy=0.7816999554634094\n",
            "Epoch: 40, loss=0.06012331321835518, train_accuracy=0.8014166951179504, dev_accuracy=0.7979999780654907\n",
            "Epoch: 41, loss=0.05929209664463997, train_accuracy=0.8056666851043701, dev_accuracy=0.8054999709129333\n",
            "Epoch: 42, loss=0.05784047767519951, train_accuracy=0.7788000106811523, dev_accuracy=0.7723999619483948\n",
            "Epoch: 43, loss=0.05709701031446457, train_accuracy=0.8129833340644836, dev_accuracy=0.8102999925613403\n",
            "Epoch: 44, loss=0.057039301842451096, train_accuracy=0.8147833347320557, dev_accuracy=0.814300000667572\n",
            "Epoch: 45, loss=0.0554196760058403, train_accuracy=0.8181333541870117, dev_accuracy=0.8183000087738037\n",
            "Epoch: 46, loss=0.05493582785129547, train_accuracy=0.8272166848182678, dev_accuracy=0.8273999691009521\n",
            "Epoch: 47, loss=0.05423855036497116, train_accuracy=0.8334167003631592, dev_accuracy=0.8330999612808228\n",
            "Epoch: 48, loss=0.05372745171189308, train_accuracy=0.8321166634559631, dev_accuracy=0.835599958896637\n",
            "Epoch: 49, loss=0.05327178165316582, train_accuracy=0.8321666717529297, dev_accuracy=0.8327999711036682\n",
            "Epoch: 50, loss=0.053032197058200836, train_accuracy=0.826533317565918, dev_accuracy=0.8265999555587769\n",
            "Epoch: 51, loss=0.05230560526251793, train_accuracy=0.8354166746139526, dev_accuracy=0.8370999693870544\n",
            "Epoch: 52, loss=0.05095961317420006, train_accuracy=0.8348833322525024, dev_accuracy=0.8375999927520752\n",
            "Epoch: 53, loss=0.05069669336080551, train_accuracy=0.8334500193595886, dev_accuracy=0.8330999612808228\n",
            "Epoch: 54, loss=0.049652017652988434, train_accuracy=0.8222000002861023, dev_accuracy=0.8251999616622925\n",
            "Epoch: 55, loss=0.049217138439416885, train_accuracy=0.8197833299636841, dev_accuracy=0.821399986743927\n",
            "Epoch: 56, loss=0.048540372401475906, train_accuracy=0.8419333696365356, dev_accuracy=0.8428999781608582\n",
            "Epoch: 57, loss=0.04847440496087074, train_accuracy=0.8391833305358887, dev_accuracy=0.8400999903678894\n",
            "Epoch: 58, loss=0.047607891261577606, train_accuracy=0.8344333171844482, dev_accuracy=0.8362999558448792\n",
            "Epoch: 59, loss=0.04756902903318405, train_accuracy=0.8452333211898804, dev_accuracy=0.8412999510765076\n",
            "Epoch: 60, loss=0.04696880653500557, train_accuracy=0.8291500210762024, dev_accuracy=0.8276999592781067\n",
            "Epoch: 61, loss=0.046593088656663895, train_accuracy=0.8399666547775269, dev_accuracy=0.8337999582290649\n",
            "Epoch: 62, loss=0.04655378684401512, train_accuracy=0.852316677570343, dev_accuracy=0.8509999513626099\n",
            "Epoch: 63, loss=0.045591920614242554, train_accuracy=0.8518166542053223, dev_accuracy=0.8470999598503113\n",
            "Epoch: 64, loss=0.04521334543824196, train_accuracy=0.8605999946594238, dev_accuracy=0.858299970626831\n",
            "Epoch: 65, loss=0.0450386144220829, train_accuracy=0.8577333688735962, dev_accuracy=0.8569999933242798\n",
            "Epoch: 66, loss=0.044511616230010986, train_accuracy=0.8412166833877563, dev_accuracy=0.8382999897003174\n",
            "Epoch: 67, loss=0.04465124011039734, train_accuracy=0.8586833477020264, dev_accuracy=0.8569999933242798\n",
            "Epoch: 68, loss=0.04400962218642235, train_accuracy=0.8585667014122009, dev_accuracy=0.8563999533653259\n",
            "Epoch: 69, loss=0.04400612413883209, train_accuracy=0.8589000105857849, dev_accuracy=0.8550999760627747\n",
            "Epoch: 70, loss=0.04370766133069992, train_accuracy=0.8564333319664001, dev_accuracy=0.8531999588012695\n",
            "Epoch: 71, loss=0.04325859993696213, train_accuracy=0.8680000305175781, dev_accuracy=0.8631999492645264\n",
            "Epoch: 72, loss=0.04248318448662758, train_accuracy=0.8701000213623047, dev_accuracy=0.8669999837875366\n",
            "Epoch: 73, loss=0.04226670786738396, train_accuracy=0.8671500086784363, dev_accuracy=0.864799976348877\n",
            "Epoch: 74, loss=0.04210707172751427, train_accuracy=0.8707333207130432, dev_accuracy=0.8646000027656555\n",
            "Epoch: 75, loss=0.041780151426792145, train_accuracy=0.8718667030334473, dev_accuracy=0.8658999800682068\n",
            "Epoch: 76, loss=0.04165922850370407, train_accuracy=0.8738833665847778, dev_accuracy=0.8698999881744385\n",
            "Epoch: 77, loss=0.04142257198691368, train_accuracy=0.8715500235557556, dev_accuracy=0.8686999678611755\n",
            "Epoch: 78, loss=0.041470106691122055, train_accuracy=0.8729666471481323, dev_accuracy=0.8654999732971191\n",
            "Epoch: 79, loss=0.04095054045319557, train_accuracy=0.8780500292778015, dev_accuracy=0.8733999729156494\n",
            "Epoch: 80, loss=0.04052716866135597, train_accuracy=0.875249981880188, dev_accuracy=0.8657999634742737\n",
            "Epoch: 81, loss=0.04040265828371048, train_accuracy=0.8823000192642212, dev_accuracy=0.8761999607086182\n",
            "Epoch: 82, loss=0.039827849715948105, train_accuracy=0.87868332862854, dev_accuracy=0.8730999827384949\n",
            "Epoch: 83, loss=0.03976498171687126, train_accuracy=0.8812833428382874, dev_accuracy=0.875499963760376\n",
            "Epoch: 84, loss=0.03944502770900726, train_accuracy=0.8658666610717773, dev_accuracy=0.8618999719619751\n",
            "Epoch: 85, loss=0.03952869772911072, train_accuracy=0.8615666627883911, dev_accuracy=0.8568999767303467\n",
            "Epoch: 86, loss=0.03901565819978714, train_accuracy=0.8765000104904175, dev_accuracy=0.8700999617576599\n",
            "Epoch: 87, loss=0.03915544971823692, train_accuracy=0.8784000277519226, dev_accuracy=0.8730999827384949\n",
            "Epoch: 88, loss=0.0392146073281765, train_accuracy=0.8693000078201294, dev_accuracy=0.8639999628067017\n",
            "Epoch: 89, loss=0.038803357630968094, train_accuracy=0.8709999918937683, dev_accuracy=0.8664000034332275\n",
            "Epoch: 90, loss=0.03813774883747101, train_accuracy=0.8809000253677368, dev_accuracy=0.8720999956130981\n",
            "Epoch: 91, loss=0.037838414311409, train_accuracy=0.8782333135604858, dev_accuracy=0.8707000017166138\n",
            "Epoch: 92, loss=0.03767937049269676, train_accuracy=0.8767666816711426, dev_accuracy=0.8705999851226807\n",
            "Epoch: 93, loss=0.03747791796922684, train_accuracy=0.8770999908447266, dev_accuracy=0.8696999549865723\n",
            "Epoch: 94, loss=0.03710154443979263, train_accuracy=0.8741333484649658, dev_accuracy=0.8650999665260315\n",
            "Epoch: 95, loss=0.03742207959294319, train_accuracy=0.8744000196456909, dev_accuracy=0.865399956703186\n",
            "Epoch: 96, loss=0.037287723273038864, train_accuracy=0.8316333293914795, dev_accuracy=0.8291999697685242\n",
            "Epoch: 97, loss=0.03723546862602234, train_accuracy=0.8738000392913818, dev_accuracy=0.8657000064849854\n",
            "Epoch: 98, loss=0.036455173045396805, train_accuracy=0.8682166934013367, dev_accuracy=0.8622999787330627\n",
            "Epoch: 99, loss=0.03620769456028938, train_accuracy=0.8806833624839783, dev_accuracy=0.8736000061035156\n",
            "Epoch: 100, loss=0.03554510697722435, train_accuracy=0.8909000158309937, dev_accuracy=0.8830999732017517\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}